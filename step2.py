# -*- coding: utf-8 -*-
"""step2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-QTrFC7Gq09nAtC69yueqEeBwqkutFe
"""

!pip install clearml

import os
os.environ["CLEARML_API_ACCESS_KEY"] = "91A7AJN241YMJXE40LLNSX198E0JK4"
os.environ["CLEARML_API_SECRET_KEY"] = "m4S8vxmP0P5m3EZAZ_0IO6t1_5L2rz15bCyxYc5VS0kcQxlb4wUH2NLDzHT9kEus_z4"
os.environ["CLEARML_API_HOST"] = "https://api.clear.ml"
os.environ["CLEARML_WEB_HOST"] = "https://app.clear.ml"
os.environ["CLEARML_FILES_HOST"] = "https://files.clear.ml"

from clearml import Task, Dataset

task = Task.init(
    project_name="plantdataset",
    task_name="Step 2 - Data Preprocessing (Pipeline Clean Run)",
    task_type=Task.TaskTypes.data_processing
)

dataset = Dataset.get(dataset_id="105163c10d0a4bbaa06055807084ec71")
dataset_path = dataset.get_local_copy()

from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

train_dir = os.path.join(dataset_path, "train")
full_dataset = datasets.ImageFolder(train_dir, transform=transform)

train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)

task.connect_configuration({"classes": full_dataset.classes})
print("✅ Step 2 complete. Classes found:", full_dataset.classes)

# ✅ Finalize task cleanly (optional but recommended)
task.close()